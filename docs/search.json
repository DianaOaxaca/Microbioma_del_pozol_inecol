[
  {
    "objectID": "04.Taxonomy.html",
    "href": "04.Taxonomy.html",
    "title": "Asignación taxonómica",
    "section": "",
    "text": "GTDB-tk\nGTDB-Tk es una herramienta que asigna taxonomía a genomas utilizando la base de datos GTDB (Genome Taxonomy Database). Basado en árboles filogenéticos y medidas de ANI (Average Nucleotide Identity), GTDB-Tk clasifica genomas bacterianos y arqueanos, proporciona una taxonomía coherente y actualizada. Se utiliza mucho en el análisis de genomas y metagenomas.\n\n\n\nGTDB-tk Workflow\n\n\nRecordemos que ya tenemos un set de bins refinados y desreplicados. Ahora vamos a asignarles identidad taxonómica, para ello vamos a correr GTDB-tk\n\n\n\n\n\n\nActiva el ambiente de gtdbtk\n\n\n\nconda activate gtdbtk-2.3.2\n\n\nEl directorio de resultados para gtdbtk ya lo tienes en tu carpeta de resultados. Para colocar los bins refinados y renombrados ejecuta el script `src/copiar_renombrarbins.sh` :\n bash src/copiar_renombrarbins.sh\nAhora si, vamos a correr gtdbtk\nnano src/10.gtdbtk.slurm\n#!/bin/bash\n#SBATHC -J gtdbtk\n#SBATCH -t 0\n#SBATCH -n 4\n#SBATCH -e outs/10.gtdbtk2.err\n#SBATCH -o outs/10.gtdbtk2.out\n#SBATCH --export=ALL\n#SBATCH -p q2\n#SBATCH -w compute4\n\n\n# Llamamos a la base de datos\nexport GTDBTK_DATA_PATH=/tmp/databases/gtdb-tk/release207_v2\n\n# ahora si corremos gtdbtk\ngtdbtk classify_wf --genome_dir results/10.gtdbtk/bins/ --out_dir results/10.gtdbtk/ --cpus 4 -x fasta --mash_db /tmp/databases/gtdb-tk/release207_v2/mash/ # --skip_ani_screen\n\n\n\n\n\n\nResultado de GTDB-Tk\n\n\n\nSi gtdbtk está tomando mucho tiempo puedes parar el proceso con ctrl + C en tu teclado. El resultado final se encuentra en el directorio y archivo: results/10.gtdbtk/gtdbtk.bac120.summary.tsv que se copió desde el inicio.\n\n\nDespués de ejecutar GTDB-tk, continuaremos en R para visualizar los datos.\nlibrary(tidyverse)\nlibrary(ggplot2)\n# Leer la tabla ------------------------------------------------------------####\nGTDBtk &lt;- read.table(\"gtdbtk.bac120.summary.tsv\", \n                    sep = \"\\t\", header = TRUE, na.strings = \"\", \n                    stringsAsFactors = FALSE) %&gt;%\n  as_tibble()\n\n# Transformar datos --------------------------------------------------------####\n\npozol_gtdbtk &lt;- GTDBtk %&gt;%\n  select(user_genome, classification) %&gt;%\n  separate(classification, c(\n    \"Domain\", \"Phylum\", \"Class\", \"Order\", \"Family\", \"Genus\", \"Species\"), \n    sep = \";\") %&gt;%\n  rename(Bin_name = user_genome) %&gt;%\n  unite(Bin_name_2, c(\"Bin_name\", \"Phylum\"), remove = FALSE) %&gt;%\n  select(Bin_name, Domain, Phylum, Class, Order, Family, Genus, Species)\n\n# Guardamos los datos en un archivo de metadatos ---------------------------####\nwrite.table(pozol_gtdbtk, file = \"Metadatos.txt\", \n            sep = \"\\t\", quote = FALSE, row.names = FALSE, col.names = TRUE)\n\n# Visualización de Datos ---------------------------------------------------####\nGTDBtk_barplot &lt;- pozol_gtdbtk %&gt;%\n  count(Phylum, Genus) %&gt;%\n  rename(Number_of_MAGs = n) %&gt;%\n  ggplot(aes(x = Phylum, y = Number_of_MAGs, fill = Genus)) + \n  geom_bar(stat = \"identity\", position = position_dodge()) +\n  theme_minimal()\n\nGTDBtk_barplot\n\n\n\n\n\n\nDiscusión\n\n\n\nEn equipos revisen los resultados generados por GTDB-tk y propongan un plan para mejorar la identificación taxonómica, qué harían para darle más soporte a estos resultados?"
  },
  {
    "objectID": "Creditos.html",
    "href": "Creditos.html",
    "title": "Créditos",
    "section": "",
    "text": "Autoras: Diana Hernández Oaxaca @DianaOaxaca y Mirna Rosas Vázquez Landa @MirnaVazquez .\nAgradecimientos:\n\nTodos los miembros del laboratorio LandaLab del Departamento de Ecología Molecular y genómica poblacional del ICMyL de la UNAM, por la sugerencias a la mejora de este tutorial.\nAl M. en C. Rafael López Sánchez, por donar los datos de metagenómica del pozol libres de maíz.\nAl Dr. Enrique Ibarra-Laclette por la organización del curso y brindar apoyo y acceso al servidor de trabajo.\nAl M. en C. Emanuel Villafán de la Torre de la Red de Estudios Moleculares Avanzados del INECOL por la instalación y soporte de las herramientas usadas en este taller.\n\n\nEl material de esta práctica inicialmente se preparó para los Talleres Internacionales de Bioinformática (TIB2022) organizados por la Sociedad Mexicana de Bioinformática (SMB) y la Comunidad de Desarrollo de Software Bioinformático (CDSB). Se ha usado en talleres intersemestrales del Instituto de Ciencias del Mar y Limnología (ICMyL) de la UNAM, el tópico de posgrado Hackeando las comunidades microbianas. Cursos intensivos de posgrado del INECOL, el taller de metagenómica de la Red Mexicana de Bioinformática RMB organizado en el CIBNOR Junio 2024 y el taller de Ciencia de Frontera en el Tecnológico de Campeche en Agosto de 2024.\nEl material se ha ido modificando con el tiempo y sigue en desarrollo. Si tienes sugerencias para agregar y/o modificar este material puedes escribirlas aquí\nContacto: hoaxacadiana@gmail.com y mvazquez@cmarl.unam.mx"
  },
  {
    "objectID": "Recursos_extra.html",
    "href": "Recursos_extra.html",
    "title": "Recursos extra",
    "section": "",
    "text": "Metagenómica\n\nLección de introducción a bash, R y metagenómica de Software Carpentry que cubre los siguientes puntos:\n\nOrganización de un proyecto metagenómico: link\nIntroducción a la línea de comandos: link\nIntroducción a R: link\nPreprocesamiento y visualización de datos metagenómicos: link\n\n\n\n\nSitio web de Anvio, canal de YouTube y canal de DIscord.\n\n\n\nR\nRladies Morelia\nRladies Cuernavaca\nRladies Xalapa\n\n\nDiscord\nPuedes unirte a nuestro canal de discord y postear dudas, proporcionar ayuda y en general armar comunidad."
  },
  {
    "objectID": "03.Binning.html",
    "href": "03.Binning.html",
    "title": "Genomas a partir de metagenomas",
    "section": "",
    "text": "La metagenómica hace referencia al estudio de todo el ADN de los organismos que se encuentran en un ambiente. La secuenciación de este material genético produce lecturas que pueden ensamblarse para conocer la diversidad microbiana y sus funciones.\nTípicamente los metagenomas pueden estudiarse mediante dos aproximaciones:\nEn este apartado nos enfocaremos en la segunda aproximación. Los MAGs se reconstruyen a partir de un ensamble metagenómico, los contigs de dicho ensamble se agrupan mediante la información de cobertura y frecuencia de tetranucleótidos. Esta agrupación puede generar errores, por lo que es indispensable evaluar la calidad de los MAGs mediante la completitud y redundancia de genes de copia única (MerenLab y col.)\nPara obtener MAGs podemos seguir el siguiente flujo de análisis:\nEn los días anteriores aprendieron a evaluar la calidad de las lecturas, filtrarlas y ensamblarlas, por lo que este apartado comenzará con un ensamble ya generado.\nDe acuerdo con el flujo de análisis (Figura 2), debemos partir de un ensamble, mapear las lecturas y obtener un archivo de profundidad de cada contig en el ensamble."
  },
  {
    "objectID": "03.Binning.html#binning",
    "href": "03.Binning.html#binning",
    "title": "Genomas a partir de metagenomas",
    "section": "Binning",
    "text": "Binning\nAhora si, vamos a agrupar los contigs del metaensamble en bins …\n\nMetabat2\nMetabat2 es una herramienta que agrupa los contigs tomando la cobertura de cada contig y calcula su composición nucleotídica.\nPara correr metabat necesitamos activar el ambiente conda donde se aloja.\n\n\n\nMetabat2. Kang et al., 2015. DOI:10.7717/peerj.1165\n\n\n\n\n\n\n\n\nActivar ambiente para Metabat2\n\n\n\n\nconda activate metabat2\n\n\n\nAhora que ya tenemos el ambiente activado vamos a crear nuestro script de slurm para ejecutarlo.\nnano src/04.metabat.slurm\n#!/bin/bash\n#SBATHC -J Metabat2 \n#SBATCH -t 0\n#SBATCH -e outs/04.metabat.err\n#SBATCH -o outs/04.metabat.out\n#SBATCH --export=ALL\n#SBATCH -n 6\n#SBATCH -N 1\n#SBATCH -p q2\n#SBATCH --mem 24G\n\nmetabat2 -i results/02.ensambles/48hrs.fasta -a results/03.profundidad/48hrs.mgh_depth.txt -o results/04.metabat/metabat -t 6 -m 1500\nGuarda tecleando ctrl + o enter y después ctrl + x enter\nY ejecuta:\nsbatch src/04.metabat.slurm\n\n\n\n\n\n\nResponde:\n\n\n\n\n\n\n¿Cuántos bins se formaron?\n\n\n\n\n\n\n\nAyuda\n\n\n\n\n\n\nls results/04.metabat/\n\n\n\n\n\n\n\nYa que corrimos Metabat2 vamos a ejecutar MaxBin2, pero primero necesitamos desactivar el ambiente:\n\n\n\n\n\n\nDesactiva el ambiente\n\n\n\nPara desactivar el ambiente debemos correr la siguiente linea:\nconda deactivate\n\n\n\n\nMaxBin2\nMaxBin2 agrupa los contigs de acuerdo a la información de cobertura, composición nucleotídica y genes de marcadores de copia única.\nVamos a ejecutarlo, activemos el ambiente conda donde se encuentra maxbin.\n\n\n\n\n\n\nActivar ambiente para MaxBin2\n\n\n\n\nconda activate metagenomics\n\n\n\n\n\n\nMaxBin2. Wu et al., 2014. https://doi.org/10.1186/2049-2618-2-26\n\n\nAhora si, vamos a crear el script y ejecutarlo.\nnano src/05.maxbin.slurm\n#!/bin/bash\n#SBATHC -J Maxbin \n#SBATCH -t 0\n#SBATCH -e outs/05.maxbin.err\n#SBATCH -o outs/05.maxbin.out\n#SBATCH --export=ALL\n#SBATCH -n 6\n#SBATCH -N 1\n#SBATCH -p q2\n#SBATCH --mem 24G\n\n#Crea el directorio para los resultados de MaxBin2\n\nmkdir -p results/05.maxbin\n\n# Linea para correrlo\n\nrun_MaxBin.pl -thread 6 -min_contig_length 1500 -contig results/02.ensambles/48hrs.fasta -out results/05.maxbin/48hrs_maxbin -abund results/03.profundidad/48hrs.mgh_depth.txt\nY lo ejecutamos:\nsbatch src/05.maxbin.slurm\n\n\n\n\n\n\nResponde:\n\n\n\nResponde\n1. ¿Cuántos bins se formaron?\n2. ¿Qué porcentaje de completitud tienen??\n\n\n\n\n\n\nSolución\n\n\n\n\n\n\nls results/05.maxbin/*.fasta | wc -l\ncat results/05.maxbin/48hrs_maxbin.summary | column -t\n\n\n\n\n\n\n\n\n\n\n\n\nDesactiva el ambiente\n\n\n\nconda deactivate\n\n\n\n\nVamb\nVAMB utiliza una combinación de enfoques de aprendizaje profundo y técnicas de agrupamiento basándose en sus patrones de composición de nucleótidos y en la co-ocurrencia de sus frecuencias de cobertura.\n\n\n\n\n\n\nActiva el ambiente binning\n\n\n\n\nconda activate mt-vamb\n\n\n\nCrea el script para vamb:\n#!/bin/bash\n#SBATHC -J Vamb \n#SBATCH -t 0\n#SBATCH -e outs/06.vamb.err\n#SBATCH -o outs/06.vamb.out\n#SBATCH --export=ALL\n#SBATCH -n 6\n#SBATCH -N 1\n#SBATCH -p q2\n#SBATCH --mem 32G\n\n#Crea el directorio para los resultados de vamb\nmkdir -p results/06.vamb\n\n# La linea para vamb\nvamb --fasta results/02.ensambles/48hrs.fasta --bamfiles results/03.profundidad/48hrs_sorted.bam --minfasta 500000 --outdir results/06.vamb/48hrs\n\n\n\n\n\n\nImportant\n\n\n\nSi quisieras recuperar los genomas de virus ¿Qué cambiarías?\n\n\n\n\n\n\n\n\nOtros programas para binning\n\n\n\nRecientemente se publicó COMEBin, que utiliza un enfoque distinto a lo que hemos usado en este tutorial. En el siguiente link encontrarás el manual y una explicación general sobre su funcionamiento.\n\n\n\n\n\n\n\n\nNo olvides descatvar el ambiente\n\n\n\nconda deactivate"
  },
  {
    "objectID": "03.Binning.html#responde",
    "href": "03.Binning.html#responde",
    "title": "Genomas a partir de metagenomas",
    "section": "Responde",
    "text": "Responde\n1. ¿Cuántos bins se formaron?\n2. ¿Qué porcentaje de completitud tienen??\n\n\n\n\n\n\nSolución\n\n\n\n\n\n\nls results/05.maxbin/*.fasta | wc -l\ncat results/05.maxbin/48hrs_maxbin.summary | column -t"
  },
  {
    "objectID": "03.Binning.html#refinamiento",
    "href": "03.Binning.html#refinamiento",
    "title": "Genomas a partir de metagenomas",
    "section": "Refinamiento",
    "text": "Refinamiento\nYa corrimos tres programas de binning, pero, recordemos que los agrupamientos pueden tener errores:\n\n\n\nContaminación de bins\n\n\nPara disminuir la contaminación e incrementar la completitud hay algunos programas que pueden ayudarnos. Entre ellos están Binning_refiner y DASTool.\n\nCheckM\nAntes de proceder al refinamiento es necesario tener claro cómo se evalúa la completitud y contaminación de los bins. Para esta evaluación se usa CheckM que se ha convertido en una herramienta estándar para la evaluación de la calidad de genomas y MAGs, y es usada por la mayoría de programas de refinamiento.\nPara hacer esta evaluación, CheckM utiliza una serie de herramientas: tree organiza los genomas en un árbol de referencia. tree_qa evalúa la cantidad de genes marcadores filogenéticos y su ubicación en el árbol. El comando lineage_set crea un archivo de marcadores específicos de linaje, que se usa en el comando analyze para evaluar la integridad y contaminación de los genomas. Finalmente, el comando qa genera tablas que resumen la calidad de los genomas.\n\n\n\nCheckM Workflow\n\n\nEn este taller no vamos a correr CheckM para los resultados de cada binneador porque uno de los programas de refinamiento que usaremos ya lo corren de forma interna, sin embargo, es útil correrlo para tener una idea clara sobre la calidad de los bins que vamos obteniendo.\nVamos a correrlo sólo como ejemplo para los resultados de Vamb para que podamos conocerlo.\nActivamos el ambiente:\nconda activate checkm\n#!/bin/bash\n#SBATHC -J checkm \n#SBATCH -t 0\n#SBATCH -e outs/06b.checkm.err\n#SBATCH -o outs/06b.checkm.out\n#SBATCH --export=ALL\n#SBATCH -n 6\n#SBATCH -N 1\n#SBATCH -p q2\n#SBATCH --mem 32G\n\n#Crea el directorio para los resultados de vamb\nmkdir -p results/06.vamb\n\n# La linea para vamb\nvamb --fasta results/02.ensambles/48hrs.fasta --bamfiles results/03.profundidad/48hrs_sorted.bam --minfasta 500000 --outdir results/06.vamb/48hrs\n\n# Ejemplo de como correrlo con los bins de vamb\n# llamamos a las bases de datos\nexport CHECKM_DATA_PATH=/lustre/databases/metagenomica/checkM/\n\n# ejecutamos checkm\ncheckm lineage_wf results/06.vamb/48hrs/bins/ results/06.vamb/48hrs/checkm -x fna -t 4 -f results/06.vamb/48hrs/checkm_vamb.txt\nY ahora si, a refinar los bins … 🥳\n\n\nBinning_refiner\nBinning_refiner se enfoca en refinar y fusionar los bins para mejorar la integridad y reducir la contaminación. Identifica bins que pueden representar el mismo genoma y los fusiona. Después elimina posibles contaminaciones, durante el proceso, Binning_refiner evalúa la calidad de los bins.\n\n\n\n\n\n\n\nBinning_refiner\n\n\nhttps://doi.org/10.1093/bioinformatics/btx086\nNecesitamos crear el directorio de resultados para binning_refiner y un directorio con los bins generados por cada programa\nmkdir -p results/07.binning_refiner/48hrsbins/{metabat,maxbin,vamb}\nAhora vamos a crear ligas simbólicas de los bins generados por cada herramienta.\n#metabat\ncd results/07.binning_refiner/48hrsbins/metabat/\n\nln -s ../../../04.metabat/*.fa .\n\n#maxbin\ncd ../maxbin/\nln -s ../../../05.maxbin/*.fasta .\n\n# vamb\ncd ../vamb/\nln -s ../../../06.vamb/48hrs/bins/*.fna .\n\n\n#regresar\ncd ../../\nAhora si, corramos Binning_refiner\nconda activate mt-das-tool\nBinning_refiner -i 48hrsbins/ -p 48hrs\nY regresemos a nuestro directorio principal\ntaller_metagenomica_pozol/\nExploremos los resultados!\ncat results/07.binning_refiner/48hrs_Binning_refiner_outputs/48hrs_sources_and_length.txt\nCopia y pega este contenido en la consola de Rscript\n# Cargar las librerias\nlibrary(dplyr)\nlibrary(networkD3)\n\n# revisa tu ubicación\ngetwd()\n\n# OJO\nsetwd(\"/home/ELALUMNOQUEERES/taller_metagenomica_pozol\")\n\n# Cargar los datos\nsankey_data &lt;- read.csv(\"results/07.binning_refiner/48hrs_Binning_refiner_outputs/48hrs_sankey.csv\")\n\n# Crear una lista de nodos únicos\nnodes &lt;- data.frame(name = unique(c(sankey_data$C1, sankey_data$C2)))\n\n# Crear el dataframe de enlaces\nlinks &lt;- sankey_data %&gt;%\n  mutate(source = match(C1, nodes$name) - 1,\n         target = match(C2, nodes$name) - 1,\n         value = Length_Kbp) %&gt;%\n  select(source, target, value)\n\n# Crear el gráfico Sankey\nsankey_plot &lt;- sankeyNetwork(Links = links, Nodes = nodes,\n                             Source = \"source\", Target = \"target\",\n                             Value = \"value\", NodeID = \"name\",\n                             fontSize = 12, nodeWidth = 30)\n\n# Mostrar el gráfico\nsankey_plot\n\n# Guardar\nlibrary(htmlwidgets)\nsaveWidget(sankey_plot, file = \"48hrs_sankey_plot.html\")\n\n\n\nBinning_refiner sankey plot\n\n\n\n\nDASTool\nDASTool es una herramienta utilizada para mejorar la calidad de los bins. Evalúa la integridad, combina los resultados de diferentes bineadores y por consenso selecciona los mejores bins de cada herramienta. Una vez que DASTool ha seleccionado los mejores bins, realiza un proceso de refinamiento para optimizar los resultados.\n\n\n\nDASTool\n\n\nVamos a correr DASTool … 🥳\nnano src/08.dastool.slurm\n#!/bin/bash\n#SBATHC -J dastool\n#SBATCH -t 0\n#SBATCH -e outs/08.dastool.err\n#SBATCH -o outs/08.dastool.out\n#SBATCH --export=ALL\n#SBATCH -n 6\n#SBATCH -N 1\n#SBATCH -p q2\n#SBATCH --mem 32G\n\nexport LC_ALL=en_US.UTF-8\n\n# Crear el directorio para los resultados\nmkdir -p results/08.dastool\n\n# DASTool necesita como entrada un archivo tabular con información de los resultados de cada programa de binning.\nFasta_to_Contig2Bin.sh -i results/04.metabat/ -e fa &gt; results/08.dastool/48hrs_metabat.dastool.tsv\nFasta_to_Contig2Bin.sh -i results/05.maxbin/ -e fasta &gt; results/08.dastool/48hrs_maxbin.dastool.tsv\nFasta_to_Contig2Bin.sh -i results/06.vamb/48hrs/bins/ -e fna &gt; results/08.dastool/48hrs_vamb.dastool.tsv\n\n# Ya que tenemos los archivos tsv podemos empezar con el refinamiento!!\nDAS_Tool -i results/08.dastool/48hrs_metabat.dastool.tsv,results/08.dastool/48hrs_maxbin.dastool.tsv,results/08.dastool/48hrs_vamb.dastool.tsv -l metabat,maxbin,vamb -c results/02.ensambles/48hrs.fasta -o results/08.dastool/48hrs -t 4 --write_bins"
  },
  {
    "objectID": "03.Binning.html#dereplicación",
    "href": "03.Binning.html#dereplicación",
    "title": "Genomas a partir de metagenomas",
    "section": "Dereplicación",
    "text": "Dereplicación\n\ndRep\nLa desreplicación es el proceso de identificar conjuntos de genomas que son “iguales” en una lista de genomas y eliminar todos los genomas excepto el “mejor” de cada conjunto redundante. dRep es una herramienta útil para esto.\n\n\n\n\n\n\n\ndRep\n\n\nYa que tenemos los resultados de los dos refinadores ejecutaremos dRep para desreplicar y seleccionar el mejor representante de cada bin.\nPrimero vamos a crear el directorio de resultados para dRep.\nmkdir -p results/09.drep/bins\nY entraremos al directorio bins dentro del directorio de resultados para colocar los bins que queremos comparar. En este caso los generados por ambos refinadores.\ncd results/09.drep/bins/\nCon las siguientes lineas podemos copiar los bins en este directorio:\nfor i in $(ls ../../08.dastool/48hrs_DASTool_bins/*.fa) ; do name=$(basename $i .fa); cp $i $name\".fasta\" ; done\n\ncp ../../07.binning_refiner/48hrs_Binning_refiner_outputs/48hrs_refined_bins/*.fasta .\nYa que los copiamos, regresemos al directorio principal.\ncd && cd taller_metagenomica_pozol/\nY ahora si, vamos a correr dRep …\n#!/bin/bash\n#SBATHC -J drep\n#SBATCH -t 0\n#SBATCH -e outs/09.drep.err\n#SBATCH -o outs/09.drep.out\n#SBATCH --export=ALL\n#SBATCH -n 1\n#SBATCH -N 1\n#SBATCH -p q2\n#SBATCH --mem 160G\n\nexport CHECKM_DATA_PATH=/lustre/apps/spack/opt/spack/linux-centos8-ivybridge/gcc-8.3.1/miniconda3-4.7.12.1-ubp7tlghaseisza4pqufq6sbehwa4pog/envs/mt-das-tool/db\n\nif [[ -d results/09.drep/bins ]]\nthen\n        rm -fr results/09.drep/bins\nfi\n\nmkdir -p results/09.drep/bins\n\ncd results/09.drep/bins/\n\nfor i in $(ls ../../08.dastool/48hrs_DASTool_bins/*.fa)\n        do name=$(basename $i .fa) \n        cp $i $name\".fasta\" \ndone\n\ncp ../../07.binning_refiner/48hrs_Binning_refiner_outputs/48hrs_refined_bins/*.fasta .\n\ncd ../../..\n\ndRep dereplicate results/09.drep/ --debug -p 1 -comp 50 -con 10 -g results/09.drep/bins/*.fasta\nEste es uno de los plots generados por dRep, que representa los mejores bins desreplicados.\n\n\n\ndRepWinningGenomes\n\n\nVamos a desactivar el ambiente de dRep\nconda deactivate\n\n\n\n\n\n\n\nPara tomar en cuenta\n\n\n\n\nEn la vida real, si el proyecto de metagenómica que estás desarrollando tiene librerías de diferentes muestras usarías dRep entre todos los conjuntos de bins ya refinados para no tener redundancia de genomas.\nQué harías si antes de desreplicar tienes un bin que tiene 98 % de completitud y 11 % de contaminación?. dRep en automático lo descartaría.\n\nPropondrías alguna manera para quedarte con este bin y curarlo para reducir su contaminación?\nPor suerte hay más programas que pueden ayudarnos a curar nuestros bins manualmente, una herramienta útil para esto es mmgenome2\n\n\n\n\n\n\n\n\nTip\n\n\n\nYa que tenemos los bins refinados y desreplicados opcionalmente podrías reensamblarlos. La manera sería mapear las lecturas de toda la muestra a los bins finales y con las lecturas mapeadas y el bin, generar un ensamble genómico para cada uno. Con esta aproximación se genera un MAG más pulido y la contaminación se reduce.\nAunque en muchos reportes verás que los autores reensamblan sus MAGs, en otros no lo hacen y no hacerlo no está mal, pero hacerlo mejora la calidad.\n\n\n\nAhora te toca a tí\n\n\n\n\n\n\nEjercicio 2\n\n\n\nAhora te toca a tí.\n\nReúnanse en equipos y repliquen todo el flujo hasta este punto con la muestra que les toca.\nDiscutan cada resultado obtenido.\nEn la carpeta compartida de Drive busquen la presentación para el Ejercicio 2, en la diapositiva correspondiente resuman sus resultados obtenidos para que los presenten.\n\nTiempo de actividad (1.5 hr)\nTiempo de presentación de resultados (5 min por equipo)"
  },
  {
    "objectID": "02.ProjectRules.html",
    "href": "02.ProjectRules.html",
    "title": "Preparemos todo para el proyecto",
    "section": "",
    "text": "Reglas del juego\n\n\n\n\nEn este tutorial haremos el ejemplo corriendo la muestra de 48 hrs.\nSe formaran 6 equipos (2 de los tiempos 0, 9 y 24 hrs).\nLos equipos discutirán y presentarán sus resultados cuando se indique en el tutorial."
  },
  {
    "objectID": "02.ProjectRules.html#espacio-de-trabajo",
    "href": "02.ProjectRules.html#espacio-de-trabajo",
    "title": "Preparemos todo para el proyecto",
    "section": "Espacio de trabajo",
    "text": "Espacio de trabajo\n\nEntra a tu cuenta en el servidor\nEntra al directorio del proyecto\n\ncd taller_metagenomica_pozol\n\n\n\n\n\n\nDirectorio de trabajo\n\n\n\nEl directorio principal del proyecto tiene la siguiente estructura:\nsrc/ Directorio donde se alojan los scripts\nresults/ Directorio que contiene los resultados de cada análsis\nouts/ Directorio que contiene los archivos de error y de salida estándar\n\n\n\n\nLa presente práctica sólo es una representación del flujo de trabajo para el análisis metagenómico, sin embargo, no sustituye los manuales de cada programa y el flujo puede variar dependiendo del tipo de datos y pregunta de investigación, de hecho para fines del taller, con frecuencia se utilizan las lineas de comando más simples para eficientar tiempo y recursos, tómalo en cuenta.\n\nCada programa tiene una ayuda y un manual de usuario, es importante revisarlo y conocer cada parámetro que se ejecute. En terminal se puede consultar el manual con el comando man y también se puede consultar la ayuda con -h o --help, por ejemplo fastqc -h.\n\n\n\n\n\n\nImportant\n\n\n\n🧠 Para tenerlo presente\nEn bioinformática cualquier línea de comandos generará un resultado, de ahí a que esos resultados sean correctos puede haber una gran diferencia.\nEn cada paso detente a revisar la información de cada programa, lee el manual, visita foros de ayuda y selecciona los argumentos que se ajusten a las necesidades de tus datos."
  },
  {
    "objectID": "01.about.html",
    "href": "01.about.html",
    "title": "El pozol",
    "section": "",
    "text": "El pozol es un alimento ácido, fermentado a partir de maíz nixtamalizado, de importancia económica y cultural, se consume desde tiempos prehispánicos y se ha estudiado desde los años 50s.\nAlgunos puntos importantes que conocemos son:\n\n\nNo se inocula y al final de su fermentación tiene alta diversidad microbiana.\nEs muy nutritivo, tiene un alto contenido de aminoácidos esenciales.\nEs considerado como prebiótico, contiene fibras solubles y microorganismos benéficos para la salud intestinal humana.\n\n\n\n🧬🔊🦠 Imaginemos que se quiere impulsar la producción de esta bebida y para ello necesitan saber todo acerca de su naturaleza microbiana.\nUna importante industria alimenticia los contacta como expertos en ecología microbiana y les pide ayuda para descubrir los siguientes puntos:\n\n\n¿Qué actores microbianos están presentes durante el proceso de fermentación?\n¿Cómo ocurre la bioconversión del maíz durante la fermentación, quién participa y cómo lo hace? ¿Qué funciones metabólicas están ocurriendo?\n¿Cambia la comunidad microbiana a lo largo del proceso?\n\n\nLa empresa secuenció cuatro puntos de fermentación de muestras que se obtuvieron en un mercado de Campeche. Las muestras se secuenciaron con Illumina NextSeq500 con lecturas pareadas de 75 pb. Los datos están públicos bajo el Bioproject: PRJNA648868\n\n\n\n\n\n\n\n\nImportante\n\n\n\nComo las muestras contienen maíz, es indispensable remover las lecturas que correspondan al genoma del maíz, no hacerlo producirá un ensamble muy fragmentado, mayoritariamente del maíz y poco microbiano.\nEl autor del artículo amablemente nos proporcionó sus muestras libres del maíz y el código que usó para ello está disponible en un repositorio público de GitHub.\n\n\nEl artículo: López-Sánchez et al., 2023. Analysing the dynamics of the bacterial community in pozol, a Mexican fermented corn dough. 10.1099/mic.0.001355"
  },
  {
    "objectID": "00.index.html",
    "href": "00.index.html",
    "title": "Microbioma_del_pozol",
    "section": "",
    "text": "Taller de Análisis de Metagenomas, Reconstrucción de Genomas y Análisis de Amplicones.\nEn este taller introductorio aprenderemos a organizar un proyecto, analizar y visualizar datos metagenómicos; reconstruir genomas a partir de metagenomas (MAGs), a clasificar los MAGs taxonómicamente y a predecir sus genes e inferir su metabolismo."
  },
  {
    "objectID": "00.index.html#temario",
    "href": "00.index.html#temario",
    "title": "Microbioma_del_pozol",
    "section": "Temario",
    "text": "Temario\nJueves\n\n\n\nHora\nTema\n\n\n\n\n10:00 - 10:30\nIntroducción a la metagenómica\n\n\n10:30 - 11:00\nEspacio de trabajo, recapitulación.\n\n\n11:00 - 11:30\nEjercicio 1\n\n\n11:30 - 12:30\nReconstrucción de genomas\n\n\n12:30 - 12:45\nDescanso\n\n\n12:45 - 13:30\nRefinamiento\n\n\n13:30 - 14:00\nDesreplicación\n\n\n14:00 - 15:00\nComida\n\n\n15:00 - 17:00\nEjercicio 2\n\n\n17:00 - 18:00\nDiscusión de resultados\n\n\n\nViernes\n\n\n\n\n\n\n\nHora\nTema\n\n\n\n\n10:00 - 11:00\nAsignación taxonómica\n\n\n11:00 - 12:00\nPredicción génica\n\n\n12:00 - 12:30\nAnotación\n\n\n12:30 - 12:45\nDescanso\n\n\n12:45- 13:30\nPlática sobre el microbioma del chinicuil\n\n\n13:30 - 14:00\nRevisión de resultados\n\n\n14:00 - 15:00\nComida\n\n\n15:00 - 16:00\nRbims\n\n\n16:00 - 17:00\nOtras inferencias metabólicas y discusión de resultados"
  },
  {
    "objectID": "05.Metabolic.html",
    "href": "05.Metabolic.html",
    "title": "Metabolismo",
    "section": "",
    "text": "Ahora que ya tenemos los bins refinados, queremos saber qué capacidades metabólicas poseen. Para ello es necesario predecir sus genes y asignarles función.\n\nPROKKA\nProkka es una herramienta útil, usa diferentes programas para predecir genes, secuencias codificantes, tRNAs, rRNAs. Hace la traducción de CDS a aminoácidos y asigna funciones usando varias bases de datos.\n\n\n\n\n\nPara correrlo vamos a activar el ambiente en el que se aloja.\n\n\n\n\n\n\nActiva el ambiente para PROKKA\n\n\n\nconda activate mt-prokka\n\n\nTenemos el ambiente activo, ahora vamos a crear un directorio de resultados para prokka.\nmkdir -p results/11.prokka\nPara correrlo, podemos hacer un ciclo que nos permita anotar todos los bins.\nfor FASTA in $(ls results/10.gtdbtk/bins/); do LOCUSTAG=$(basename $FASTA .fasta); prokka --locustag \"${LOCUSTAG}_Scaffold\"  --prefix $LOCUSTAG --addgenes --addmrn --cpus 4 --outdir \"results/11.prokka/$LOCUSTAG\" \"results/10.gtdbtk/bins/$FASTA\" ;\ndone\n\n\n\n\n\n\nExplora\n\n\n\nMientras prokka se ejecuta en los bins que obtuviste, despliega la ayuda y discute:\n\n¿ qué argumentos quitarías o agregarías?\nCuáles te llamaron la atención?\n\n\n\nDesactivemos el ambiente:\nconda deactivate\nAhora que tenemos las proteínas predichas vamos a obtener más anotaciones útiles, usaremos kofam para esto.\n\n\nKofamScan\nKofamScan es una herramienta de anotación, usa la base de datos KOfam de KEGG para obtener información sobre los genes que participan en diferentes rutas metabólicas.\nCreamos el script para kofam\nnano src/12.kofam.slurm\n#!/bin/bash\n#SBATHC -J kofam\n#SBATCH -t 0\n#SBATCH -n 4\n#SBATCH -e outs/12.kofam.err\n#SBATCH -o outs/12.kofam.out\n#SBATCH --export=ALL\n#SBATCH -p q2\n#SBATCH -w compute4\n\n# Limpiamos por si las moscas :P\nmodule purge\n\n# Caragmos el modulo para kofam\nmodule load kofam-scan/1.3.0/gcc/8.3.1-n3v4\n\n# Creamos el directorio para alojar los resultados\nmkdir -p results/12.kofam\n\n# Lo corremos\nfor FAA in $(ls results/11.prokka/*/*.faa); do\n    name=$(basename $FAA .faa)\n    exec_annotation $FAA \\\n        -o results/12.kofam/\"$name.txt\" \\\n        --report-unannotated \\\n        --cpu 4 \\\n        --tmp-dir results/12.kofam/\"tmp$name\" \\\n        -p /tmp/databases/KOfam/profiles/ \\\n        -k /tmp/databases/KOfam/ko_list\ndone\n\n# remover los directorios temporales\nrm -r results/12.kofam/tmp*\nEstos resultados ya los tienes en el directorio results/12.kofam por si esta tardando mucho.\nY ahora que ya tenemos los identificadores de KO para cada proteína, vamos a filtrar y graficar el metabolismo de los bins.\n\n\nRbiMs\nRbiMs es un paquete de R muy útil para obtener la anotación de cada KEGG ID y generar plots de esta información. Puede trabajar con anotaciones de KOFAM, Interpro o PFAM.\n\n\n\nRbiMs\n\n\nVamos al editor de Rstudio para correr RbiMs ✨\nlibrary(tidyverse)\nlibrary(tidyr)\nlibrary(rbims)\nlibrary(readxl)\n\n#setwd(\"/home/alumnoX/taller_metagenomica_pozol/\")\n\n#A continuación, leemos los resultados de KEGG \npozol_table &lt;- read_ko(data_kofam = \"results/12.kofam/\") \n\n#y los mapeamos con la base de datos de KEGG:\npozol_mapp &lt;- mapping_ko(pozol_table)\n\n#Nos centraremos en las vías metabólicas relacionadas con la biosintesis de aminoacidos y vitaminas:\n\nOverview &lt;- c(\"Biosynthesis of amino acids\", \"Vitamin B6 metabolism\")\nAminoacids_metabolism_pozol &lt;- pozol_mapp %&gt;%\n  drop_na(Module_description) %&gt;%\n  get_subset_pathway(Pathway_description, Overview) \n\n#Visualizamos los datos con un gráfico de burbujas:\n\nplot_bubble(tibble_ko = Aminoacids_metabolism_pozol,\n            x_axis = Bin_name, \n            y_axis = Pathway_description,\n            analysis = \"KEGG\",\n            calc = \"Percentage\",\n            range_size = c(1, 10),\n            y_labs = FALSE,\n            x_labs = FALSE)  \n\n#Añadiremos metadatos, como la taxonomía:\n\nMetadatos &lt;- read_delim(\"results/10.gtdbtk/Metadatos.txt\", delim = \"\\t\")\n\n#Y generaremos un gráfico de burbujas con metadatos:\n\nplot_bubble(tibble_ko = Aminoacids_metabolism_pozol,\n            x_axis = Bin_name, \n            y_axis = Pathway_description,\n            analysis = \"KEGG\",\n            data_experiment = Metadatos,\n            calc = \"Percentage\",\n            color_character = Family,\n            range_size = c(1, 10),\n            y_labs = FALSE,\n            x_labs = FALSE) \n\n# Exploración de una Vía Específica\n# podemos explorar una sola vía, como el “Secretion system,” y crear un mapa de calor para visualizar los genes relacionados con esta vía:\n\nSecretion_system_pozol &lt;- pozol_mapp %&gt;%\n  drop_na(Cycle) %&gt;%\n  get_subset_pathway(Cycle, \"Secretion system\")\n\n#Y, finalmente, generamos un mapa de calor:\n\nplot_heatmap(tibble_ko = Secretion_system_pozol, \n             y_axis = Genes,\n             analysis = \"KEGG\",\n             calc = \"Binary\")\n\n#También podemos agregar metadatos para obtener una visión más completa:\n\nplot_heatmap(tibble_ko = Secretion_system_pozol, \n             y_axis = Genes,\n             data_experiment = Metadatos,\n             order_x = Family,\n             analysis = \"KEGG\",\n             calc = \"Binary\")\n\nplot_heatmap(tibble_ko = Secretion_system_pozol, \n             y_axis = Genes,\n             data_experiment = Metadatos,\n             order_y = Pathway_cycle,\n             order_x = Family,\n             analysis = \"KEGG\",\n             calc = \"Binary\")\n\n# Explorar\ncolnames(pozol_mapp) \n\npozol_mapp %&gt;%\n  select(Cycle, Pathway_cycle, Pathway_description) %&gt;%\n  distinct()\n\n\n\n\n\n\n\nAntismash\nAdicionalmente podrías anotar el metabolismo secundario de los bins siguiendo el flujo de análisis propuestos en la lección de Minería Genómica de Software Carpentry."
  }
]