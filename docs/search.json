[
  {
    "objectID": "04.Taxonomy.html",
    "href": "04.Taxonomy.html",
    "title": "Asignaci√≥n taxon√≥mica",
    "section": "",
    "text": "GTDB-tk\nGTDB-Tk es una herramienta que asigna taxonom√≠a a genomas utilizando la base de datos GTDB (Genome Taxonomy Database). Basado en √°rboles filogen√©ticos y medidas de ANI (Average Nucleotide Identity), GTDB-Tk clasifica genomas bacterianos y arqueanos, proporciona una taxonom√≠a coherente y actualizada. Se utiliza mucho en el an√°lisis de genomas y metagenomas.\n\n\n\nGTDB-tk Workflow\n\n\nRecordemos que ya tenemos un set de bins refinados y desreplicados. Ahora vamos a asignarles identidad taxon√≥mica, para ello vamos a correr GTDB-tk\n\n\n\n\n\n\nActiva el ambiente de gtdbtk\n\n\n\nconda activate gtdbtk-2.3.2\n\n\nEl directorio de resultados para gtdbtk ya lo tienes en tu carpeta de resultados. Para colocar los bins refinados y renombrados ejecuta el script `src/copiar_renombrarbins.sh` :\n bash src/copiar_renombrarbins.sh\nAhora si, vamos a correr gtdbtk\nnano src/10.gtdbtk.slurm\n#!/bin/bash\n#SBATHC -J gtdbtk\n#SBATCH -t 0\n#SBATCH -n 4\n#SBATCH -e outs/10.gtdbtk2.err\n#SBATCH -o outs/10.gtdbtk2.out\n#SBATCH --export=ALL\n#SBATCH -p q2\n#SBATCH -w compute4\n\n\n# Llamamos a la base de datos\nexport GTDBTK_DATA_PATH=/tmp/databases/gtdb-tk/release207_v2\n\n# ahora si corremos gtdbtk\ngtdbtk classify_wf --genome_dir results/10.gtdbtk/bins/ --out_dir results/10.gtdbtk/ --cpus 4 -x fasta --mash_db /tmp/databases/gtdb-tk/release207_v2/mash/ # --skip_ani_screen\n\n\n\n\n\n\nResultado de GTDB-Tk\n\n\n\nSi gtdbtk est√° tomando mucho tiempo puedes parar el proceso con ctrl + C en tu teclado. El resultado final se encuentra en el directorio y archivo: results/10.gtdbtk/gtdbtk.bac120.summary.tsv que se copi√≥ desde el inicio.\n\n\nDespu√©s de ejecutar GTDB-tk, continuaremos en R para visualizar los datos.\nlibrary(tidyverse)\nlibrary(ggplot2)\n# Leer la tabla ------------------------------------------------------------####\nGTDBtk &lt;- read.table(\"gtdbtk.bac120.summary.tsv\", \n                    sep = \"\\t\", header = TRUE, na.strings = \"\", \n                    stringsAsFactors = FALSE) %&gt;%\n  as_tibble()\n\n# Transformar datos --------------------------------------------------------####\n\npozol_gtdbtk &lt;- GTDBtk %&gt;%\n  select(user_genome, classification) %&gt;%\n  separate(classification, c(\n    \"Domain\", \"Phylum\", \"Class\", \"Order\", \"Family\", \"Genus\", \"Species\"), \n    sep = \";\") %&gt;%\n  rename(Bin_name = user_genome) %&gt;%\n  unite(Bin_name_2, c(\"Bin_name\", \"Phylum\"), remove = FALSE) %&gt;%\n  select(Bin_name, Domain, Phylum, Class, Order, Family, Genus, Species)\n\n# Guardamos los datos en un archivo de metadatos ---------------------------####\nwrite.table(pozol_gtdbtk, file = \"Metadatos.txt\", \n            sep = \"\\t\", quote = FALSE, row.names = FALSE, col.names = TRUE)\n\n# Visualizaci√≥n de Datos ---------------------------------------------------####\nGTDBtk_barplot &lt;- pozol_gtdbtk %&gt;%\n  count(Phylum, Genus) %&gt;%\n  rename(Number_of_MAGs = n) %&gt;%\n  ggplot(aes(x = Phylum, y = Number_of_MAGs, fill = Genus)) + \n  geom_bar(stat = \"identity\", position = position_dodge()) +\n  theme_minimal()\n\nGTDBtk_barplot\n\n\n\n\n\n\nDiscusi√≥n\n\n\n\nEn equipos revisen los resultados generados por GTDB-tk y propongan un plan para mejorar la identificaci√≥n taxon√≥mica, qu√© har√≠an para darle m√°s soporte a estos resultados?"
  },
  {
    "objectID": "Creditos.html",
    "href": "Creditos.html",
    "title": "Cr√©ditos",
    "section": "",
    "text": "Autoras: Diana Hern√°ndez Oaxaca @DianaOaxaca y Mirna Rosas V√°zquez Landa @MirnaVazquez .\nAgradecimientos:\n\nTodos los miembros del laboratorio LandaLab del Departamento de Ecolog√≠a Molecular y gen√≥mica poblacional del ICMyL de la UNAM, por la sugerencias a la mejora de este tutorial.\nAl M. en C. Rafael L√≥pez S√°nchez, por donar los datos de metagen√≥mica del pozol libres de ma√≠z.\nAl Dr.¬†Enrique Ibarra-Laclette por la organizaci√≥n del curso y brindar apoyo y acceso al servidor de trabajo.\nAl M. en C. Emanuel Villaf√°n de la Torre de la Red de Estudios Moleculares Avanzados del INECOL por la instalaci√≥n y soporte de las herramientas usadas en este taller.\n\n\nEl material de esta pr√°ctica inicialmente se prepar√≥ para los Talleres Internacionales de Bioinform√°tica (TIB2022) organizados por la Sociedad Mexicana de Bioinform√°tica (SMB) y la Comunidad de Desarrollo de Software Bioinform√°tico (CDSB). Se ha usado en talleres intersemestrales del Instituto de Ciencias del Mar y Limnolog√≠a (ICMyL) de la UNAM, el t√≥pico de posgrado Hackeando las comunidades microbianas. Cursos intensivos de posgrado del INECOL, el taller de metagen√≥mica de la Red Mexicana de Bioinform√°tica RMB organizado en el CIBNOR Junio 2024 y el taller de Ciencia de Frontera en el Tecnol√≥gico de Campeche en Agosto de 2024.\nEl material se ha ido modificando con el tiempo y sigue en desarrollo. Si tienes sugerencias para agregar y/o modificar este material puedes escribirlas aqu√≠\nContacto: hoaxacadiana@gmail.com y mvazquez@cmarl.unam.mx"
  },
  {
    "objectID": "Recursos_extra.html",
    "href": "Recursos_extra.html",
    "title": "Recursos extra",
    "section": "",
    "text": "Metagen√≥mica\n\nLecci√≥n de introducci√≥n a bash, R y metagen√≥mica de Software Carpentry que cubre los siguientes puntos:\n\nOrganizaci√≥n de un proyecto metagen√≥mico: link\nIntroducci√≥n a la l√≠nea de comandos: link\nIntroducci√≥n a R: link\nPreprocesamiento y visualizaci√≥n de datos metagen√≥micos: link\n\n\n\n\nSitio web de Anvio, canal de YouTube y canal de DIscord.\n\n\n\nR\nRladies Morelia\nRladies Cuernavaca\nRladies Xalapa\n\n\nDiscord\nPuedes unirte a nuestro canal de discord y postear dudas, proporcionar ayuda y en general armar comunidad."
  },
  {
    "objectID": "03.Binning.html",
    "href": "03.Binning.html",
    "title": "Genomas a partir de metagenomas",
    "section": "",
    "text": "La metagen√≥mica hace referencia al estudio de todo el ADN de los organismos que se encuentran en un ambiente. La secuenciaci√≥n de este material gen√©tico produce lecturas que pueden ensamblarse para conocer la diversidad microbiana y sus funciones.\nT√≠picamente los metagenomas pueden estudiarse mediante dos aproximaciones:\nEn este apartado nos enfocaremos en la segunda aproximaci√≥n. Los MAGs se reconstruyen a partir de un ensamble metagen√≥mico, los contigs de dicho ensamble se agrupan mediante la informaci√≥n de cobertura y frecuencia de tetranucle√≥tidos. Esta agrupaci√≥n puede generar errores, por lo que es indispensable evaluar la calidad de los MAGs mediante la completitud y redundancia de genes de copia √∫nica (MerenLab y col.)\nPara obtener MAGs podemos seguir el siguiente flujo de an√°lisis:\nEn los d√≠as anteriores aprendieron a evaluar la calidad de las lecturas, filtrarlas y ensamblarlas, por lo que este apartado comenzar√° con un ensamble ya generado.\nDe acuerdo con el flujo de an√°lisis (Figura 2), debemos partir de un ensamble, mapear las lecturas y obtener un archivo de profundidad de cada contig en el ensamble."
  },
  {
    "objectID": "03.Binning.html#binning",
    "href": "03.Binning.html#binning",
    "title": "Genomas a partir de metagenomas",
    "section": "Binning",
    "text": "Binning\nAhora si, vamos a agrupar los contigs del metaensamble en bins ‚Ä¶\n\nMetabat2\nMetabat2 es una herramienta que agrupa los contigs tomando la cobertura de cada contig y calcula su composici√≥n nucleot√≠dica.\nPara correr metabat necesitamos activar el ambiente conda donde se aloja.\n\n\n\nMetabat2. Kang et al., 2015. DOI:10.7717/peerj.1165\n\n\n\n\n\n\n\n\nActivar ambiente para Metabat2\n\n\n\n\nconda activate metabat2\n\n\n\nAhora que ya tenemos el ambiente activado vamos a crear nuestro script de slurm para ejecutarlo.\nnano src/04.metabat.slurm\n#!/bin/bash\n#SBATHC -J Metabat2 \n#SBATCH -t 0\n#SBATCH -e outs/04.metabat.err\n#SBATCH -o outs/04.metabat.out\n#SBATCH --export=ALL\n#SBATCH -n 6\n#SBATCH -N 1\n#SBATCH -p q2\n#SBATCH --mem 24G\n\nmetabat2 -i results/02.ensambles/48hrs.fasta -a results/03.profundidad/48hrs.mgh_depth.txt -o results/04.metabat/metabat -t 6 -m 1500\nGuarda tecleando ctrl + o enter y despu√©s ctrl + x enter\nY ejecuta:\nsbatch src/04.metabat.slurm\n\n\n\n\n\n\nResponde:\n\n\n\n\n\n\n¬øCu√°ntos bins se formaron?\n\n\n\n\n\n\n\nAyuda\n\n\n\n\n\n\nls results/04.metabat/\n\n\n\n\n\n\n\nYa que corrimos Metabat2 vamos a ejecutar MaxBin2, pero primero necesitamos desactivar el ambiente:\n\n\n\n\n\n\nDesactiva el ambiente\n\n\n\nPara desactivar el ambiente debemos correr la siguiente linea:\nconda deactivate\n\n\n\n\nMaxBin2\nMaxBin2 agrupa los contigs de acuerdo a la informaci√≥n de cobertura, composici√≥n nucleot√≠dica y genes de marcadores de copia √∫nica.\nVamos a ejecutarlo, activemos el ambiente conda donde se encuentra maxbin.\n\n\n\n\n\n\nActivar ambiente para MaxBin2\n\n\n\n\nconda activate metagenomics\n\n\n\n\n\n\nMaxBin2. Wu et al., 2014. https://doi.org/10.1186/2049-2618-2-26\n\n\nAhora si, vamos a crear el script y ejecutarlo.\nnano src/05.maxbin.slurm\n#!/bin/bash\n#SBATHC -J Maxbin \n#SBATCH -t 0\n#SBATCH -e outs/05.maxbin.err\n#SBATCH -o outs/05.maxbin.out\n#SBATCH --export=ALL\n#SBATCH -n 6\n#SBATCH -N 1\n#SBATCH -p q2\n#SBATCH --mem 24G\n\n#Crea el directorio para los resultados de MaxBin2\n\nmkdir -p results/05.maxbin\n\n# Linea para correrlo\n\nrun_MaxBin.pl -thread 6 -min_contig_length 1500 -contig results/02.ensambles/48hrs.fasta -out results/05.maxbin/48hrs_maxbin -abund results/03.profundidad/48hrs.mgh_depth.txt\nY lo ejecutamos:\nsbatch src/05.maxbin.slurm\n\n\n\n\n\n\nResponde:\n\n\n\nResponde\n1. ¬øCu√°ntos bins se formaron?\n2. ¬øQu√© porcentaje de completitud tienen??\n\n\n\n\n\n\nSoluci√≥n\n\n\n\n\n\n\nls results/05.maxbin/*.fasta | wc -l\ncat results/05.maxbin/48hrs_maxbin.summary | column -t\n\n\n\n\n\n\n\n\n\n\n\n\nDesactiva el ambiente\n\n\n\nconda deactivate\n\n\n\n\nVamb\nVAMB utiliza una combinaci√≥n de enfoques de aprendizaje profundo y t√©cnicas de agrupamiento bas√°ndose en sus patrones de composici√≥n de nucle√≥tidos y en la co-ocurrencia de sus frecuencias de cobertura.\n\n\n\n\n\n\nActiva el ambiente binning\n\n\n\n\nconda activate mt-vamb\n\n\n\nCrea el script para vamb:\n#!/bin/bash\n#SBATHC -J Vamb \n#SBATCH -t 0\n#SBATCH -e outs/06.vamb.err\n#SBATCH -o outs/06.vamb.out\n#SBATCH --export=ALL\n#SBATCH -n 6\n#SBATCH -N 1\n#SBATCH -p q2\n#SBATCH --mem 32G\n\n#Crea el directorio para los resultados de vamb\nmkdir -p results/06.vamb\n\n# La linea para vamb\nvamb --fasta results/02.ensambles/48hrs.fasta --bamfiles results/03.profundidad/48hrs_sorted.bam --minfasta 500000 --outdir results/06.vamb/48hrs\n\n\n\n\n\n\nImportant\n\n\n\nSi quisieras recuperar los genomas de virus ¬øQu√© cambiar√≠as?\n\n\n\n\n\n\n\n\nOtros programas para binning\n\n\n\nRecientemente se public√≥ COMEBin, que utiliza un enfoque distinto a lo que hemos usado en este tutorial. En el siguiente link encontrar√°s el manual y una explicaci√≥n general sobre su funcionamiento.\n\n\n\n\n\n\n\n\nNo olvides descatvar el ambiente\n\n\n\nconda deactivate"
  },
  {
    "objectID": "03.Binning.html#responde",
    "href": "03.Binning.html#responde",
    "title": "Genomas a partir de metagenomas",
    "section": "Responde",
    "text": "Responde\n1. ¬øCu√°ntos bins se formaron?\n2. ¬øQu√© porcentaje de completitud tienen??\n\n\n\n\n\n\nSoluci√≥n\n\n\n\n\n\n\nls results/05.maxbin/*.fasta | wc -l\ncat results/05.maxbin/48hrs_maxbin.summary | column -t"
  },
  {
    "objectID": "03.Binning.html#refinamiento",
    "href": "03.Binning.html#refinamiento",
    "title": "Genomas a partir de metagenomas",
    "section": "Refinamiento",
    "text": "Refinamiento\nYa corrimos tres programas de binning, pero, recordemos que los agrupamientos pueden tener errores:\n\n\n\nContaminaci√≥n de bins\n\n\nPara disminuir la contaminaci√≥n e incrementar la completitud hay algunos programas que pueden ayudarnos. Entre ellos est√°n Binning_refiner y DASTool.\n\nCheckM\nAntes de proceder al refinamiento es necesario tener claro c√≥mo se eval√∫a la completitud y contaminaci√≥n de los bins. Para esta evaluaci√≥n se usa CheckM que se ha convertido en una herramienta est√°ndar para la evaluaci√≥n de la calidad de genomas y MAGs, y es usada por la mayor√≠a de programas de refinamiento.\nPara hacer esta evaluaci√≥n, CheckM utiliza una serie de herramientas: tree organiza los genomas en un √°rbol de referencia. tree_qa eval√∫a la cantidad de genes marcadores filogen√©ticos y su ubicaci√≥n en el √°rbol. El comando lineage_set crea un archivo de marcadores espec√≠ficos de linaje, que se usa en el comando analyze para evaluar la integridad y contaminaci√≥n de los genomas. Finalmente, el comando qa genera tablas que resumen la calidad de los genomas.\n\n\n\nCheckM Workflow\n\n\nEn este taller no vamos a correr CheckM para los resultados de cada binneador porque uno de los programas de refinamiento que usaremos ya lo corren de forma interna, sin embargo, es √∫til correrlo para tener una idea clara sobre la calidad de los bins que vamos obteniendo.\nVamos a correrlo s√≥lo como ejemplo para los resultados de Vamb para que podamos conocerlo.\nActivamos el ambiente:\nconda activate checkm\n#!/bin/bash\n#SBATHC -J checkm \n#SBATCH -t 0\n#SBATCH -e outs/06b.checkm.err\n#SBATCH -o outs/06b.checkm.out\n#SBATCH --export=ALL\n#SBATCH -n 6\n#SBATCH -N 1\n#SBATCH -p q2\n#SBATCH --mem 32G\n\n#Crea el directorio para los resultados de vamb\nmkdir -p results/06.vamb\n\n# La linea para vamb\nvamb --fasta results/02.ensambles/48hrs.fasta --bamfiles results/03.profundidad/48hrs_sorted.bam --minfasta 500000 --outdir results/06.vamb/48hrs\n\n# Ejemplo de como correrlo con los bins de vamb\n# llamamos a las bases de datos\nexport CHECKM_DATA_PATH=/lustre/databases/metagenomica/checkM/\n\n# ejecutamos checkm\ncheckm lineage_wf results/06.vamb/48hrs/bins/ results/06.vamb/48hrs/checkm -x fna -t 4 -f results/06.vamb/48hrs/checkm_vamb.txt\nY ahora si, a refinar los bins ‚Ä¶ ü•≥\n\n\nBinning_refiner\nBinning_refiner se enfoca en refinar y fusionar los bins para mejorar la integridad y reducir la contaminaci√≥n. Identifica bins que pueden representar el mismo genoma y los fusiona. Despu√©s elimina posibles contaminaciones, durante el proceso, Binning_refiner eval√∫a la calidad de los bins.\n\n\n\n\n\n\n\nBinning_refiner\n\n\nhttps://doi.org/10.1093/bioinformatics/btx086\nNecesitamos crear el directorio de resultados para binning_refiner y un directorio con los bins generados por cada programa\nmkdir -p results/07.binning_refiner/48hrsbins/{metabat,maxbin,vamb}\nAhora vamos a crear ligas simb√≥licas de los bins generados por cada herramienta.\n#metabat\ncd results/07.binning_refiner/48hrsbins/metabat/\n\nln -s ../../../04.metabat/*.fa .\n\n#maxbin\ncd ../maxbin/\nln -s ../../../05.maxbin/*.fasta .\n\n# vamb\ncd ../vamb/\nln -s ../../../06.vamb/48hrs/bins/*.fna .\n\n\n#regresar\ncd ../../\nAhora si, corramos Binning_refiner\nconda activate mt-das-tool\nBinning_refiner -i 48hrsbins/ -p 48hrs\nY regresemos a nuestro directorio principal\ntaller_metagenomica_pozol/\nExploremos los resultados!\ncat results/07.binning_refiner/48hrs_Binning_refiner_outputs/48hrs_sources_and_length.txt\nCopia y pega este contenido en la consola de Rscript\n# Cargar las librerias\nlibrary(dplyr)\nlibrary(networkD3)\n\n# revisa tu ubicaci√≥n\ngetwd()\n\n# OJO\nsetwd(\"/home/ELALUMNOQUEERES/taller_metagenomica_pozol\")\n\n# Cargar los datos\nsankey_data &lt;- read.csv(\"results/07.binning_refiner/48hrs_Binning_refiner_outputs/48hrs_sankey.csv\")\n\n# Crear una lista de nodos √∫nicos\nnodes &lt;- data.frame(name = unique(c(sankey_data$C1, sankey_data$C2)))\n\n# Crear el dataframe de enlaces\nlinks &lt;- sankey_data %&gt;%\n  mutate(source = match(C1, nodes$name) - 1,\n         target = match(C2, nodes$name) - 1,\n         value = Length_Kbp) %&gt;%\n  select(source, target, value)\n\n# Crear el gr√°fico Sankey\nsankey_plot &lt;- sankeyNetwork(Links = links, Nodes = nodes,\n                             Source = \"source\", Target = \"target\",\n                             Value = \"value\", NodeID = \"name\",\n                             fontSize = 12, nodeWidth = 30)\n\n# Mostrar el gr√°fico\nsankey_plot\n\n# Guardar\nlibrary(htmlwidgets)\nsaveWidget(sankey_plot, file = \"48hrs_sankey_plot.html\")\n\n\n\nBinning_refiner sankey plot\n\n\n\n\nDASTool\nDASTool es una herramienta utilizada para mejorar la calidad de los bins. Eval√∫a la integridad, combina los resultados de diferentes bineadores y por consenso selecciona los mejores bins de cada herramienta. Una vez que DASTool ha seleccionado los mejores bins, realiza un proceso de refinamiento para optimizar los resultados.\n\n\n\nDASTool\n\n\nVamos a correr DASTool ‚Ä¶ ü•≥\nnano src/08.dastool.slurm\n#!/bin/bash\n#SBATHC -J dastool\n#SBATCH -t 0\n#SBATCH -e outs/08.dastool.err\n#SBATCH -o outs/08.dastool.out\n#SBATCH --export=ALL\n#SBATCH -n 6\n#SBATCH -N 1\n#SBATCH -p q2\n#SBATCH --mem 32G\n\nexport LC_ALL=en_US.UTF-8\n\n# Crear el directorio para los resultados\nmkdir -p results/08.dastool\n\n# DASTool necesita como entrada un archivo tabular con informaci√≥n de los resultados de cada programa de binning.\nFasta_to_Contig2Bin.sh -i results/04.metabat/ -e fa &gt; results/08.dastool/48hrs_metabat.dastool.tsv\nFasta_to_Contig2Bin.sh -i results/05.maxbin/ -e fasta &gt; results/08.dastool/48hrs_maxbin.dastool.tsv\nFasta_to_Contig2Bin.sh -i results/06.vamb/48hrs/bins/ -e fna &gt; results/08.dastool/48hrs_vamb.dastool.tsv\n\n# Ya que tenemos los archivos tsv podemos empezar con el refinamiento!!\nDAS_Tool -i results/08.dastool/48hrs_metabat.dastool.tsv,results/08.dastool/48hrs_maxbin.dastool.tsv,results/08.dastool/48hrs_vamb.dastool.tsv -l metabat,maxbin,vamb -c results/02.ensambles/48hrs.fasta -o results/08.dastool/48hrs -t 4 --write_bins"
  },
  {
    "objectID": "03.Binning.html#dereplicaci√≥n",
    "href": "03.Binning.html#dereplicaci√≥n",
    "title": "Genomas a partir de metagenomas",
    "section": "Dereplicaci√≥n",
    "text": "Dereplicaci√≥n\n\ndRep\nLa desreplicaci√≥n es el proceso de identificar conjuntos de genomas que son ‚Äúiguales‚Äù en una lista de genomas y eliminar todos los genomas excepto el ‚Äúmejor‚Äù de cada conjunto redundante. dRep es una herramienta √∫til para esto.\n\n\n\n\n\n\n\ndRep\n\n\nYa que tenemos los resultados de los dos refinadores ejecutaremos dRep para desreplicar y seleccionar el mejor representante de cada bin.\nPrimero vamos a crear el directorio de resultados para dRep.\nmkdir -p results/09.drep/bins\nY entraremos al directorio bins dentro del directorio de resultados para colocar los bins que queremos comparar. En este caso los generados por ambos refinadores.\ncd results/09.drep/bins/\nCon las siguientes lineas podemos copiar los bins en este directorio:\nfor i in $(ls ../../08.dastool/48hrs_DASTool_bins/*.fa) ; do name=$(basename $i .fa); cp $i $name\".fasta\" ; done\n\ncp ../../07.binning_refiner/48hrs_Binning_refiner_outputs/48hrs_refined_bins/*.fasta .\nYa que los copiamos, regresemos al directorio principal.\ncd && cd taller_metagenomica_pozol/\nY ahora si, vamos a correr dRep ‚Ä¶\n#!/bin/bash\n#SBATHC -J drep\n#SBATCH -t 0\n#SBATCH -e outs/09.drep.err\n#SBATCH -o outs/09.drep.out\n#SBATCH --export=ALL\n#SBATCH -n 1\n#SBATCH -N 1\n#SBATCH -p q2\n#SBATCH --mem 160G\n\nexport CHECKM_DATA_PATH=/lustre/apps/spack/opt/spack/linux-centos8-ivybridge/gcc-8.3.1/miniconda3-4.7.12.1-ubp7tlghaseisza4pqufq6sbehwa4pog/envs/mt-das-tool/db\n\nif [[ -d results/09.drep/bins ]]\nthen\n        rm -fr results/09.drep/bins\nfi\n\nmkdir -p results/09.drep/bins\n\ncd results/09.drep/bins/\n\nfor i in $(ls ../../08.dastool/48hrs_DASTool_bins/*.fa)\n        do name=$(basename $i .fa) \n        cp $i $name\".fasta\" \ndone\n\ncp ../../07.binning_refiner/48hrs_Binning_refiner_outputs/48hrs_refined_bins/*.fasta .\n\ncd ../../..\n\ndRep dereplicate results/09.drep/ --debug -p 1 -comp 50 -con 10 -g results/09.drep/bins/*.fasta\nEste es uno de los plots generados por dRep, que representa los mejores bins desreplicados.\n\n\n\ndRepWinningGenomes\n\n\nVamos a desactivar el ambiente de dRep\nconda deactivate\n\n\n\n\n\n\n\nPara tomar en cuenta\n\n\n\n\nEn la vida real, si el proyecto de metagen√≥mica que est√°s desarrollando tiene librer√≠as de diferentes muestras usar√≠as dRep entre todos los conjuntos de bins ya refinados para no tener redundancia de genomas.\nQu√© har√≠as si antes de desreplicar tienes un bin que tiene 98 % de completitud y 11 % de contaminaci√≥n?. dRep en autom√°tico lo descartar√≠a.\n\nPropondr√≠as alguna manera para quedarte con este bin y curarlo para reducir su contaminaci√≥n?\nPor suerte hay m√°s programas que pueden ayudarnos a curar nuestros bins manualmente, una herramienta √∫til para esto es mmgenome2\n\n\n\n\n\n\n\n\nTip\n\n\n\nYa que tenemos los bins refinados y desreplicados opcionalmente podr√≠as reensamblarlos. La manera ser√≠a mapear las lecturas de toda la muestra a los bins finales y con las lecturas mapeadas y el bin, generar un ensamble gen√≥mico para cada uno. Con esta aproximaci√≥n se genera un MAG m√°s pulido y la contaminaci√≥n se reduce.\nAunque en muchos reportes ver√°s que los autores reensamblan sus MAGs, en otros no lo hacen y no hacerlo no est√° mal, pero hacerlo mejora la calidad.\n\n\n\nAhora te toca a t√≠\n\n\n\n\n\n\nEjercicio 2\n\n\n\nAhora te toca a t√≠.\n\nRe√∫nanse en equipos y repliquen todo el flujo hasta este punto con la muestra que les toca.\nDiscutan cada resultado obtenido.\nEn la carpeta compartida de Drive busquen la presentaci√≥n para el Ejercicio 2, en la diapositiva correspondiente resuman sus resultados obtenidos para que los presenten.\n\nTiempo de actividad (1.5 hr)\nTiempo de presentaci√≥n de resultados (5 min por equipo)"
  },
  {
    "objectID": "02.ProjectRules.html",
    "href": "02.ProjectRules.html",
    "title": "Preparemos todo para el proyecto",
    "section": "",
    "text": "Reglas del juego\n\n\n\n\nEn este tutorial haremos el ejemplo corriendo la muestra de 48 hrs.\nSe formaran 6 equipos (2 de los tiempos 0, 9 y 24 hrs).\nLos equipos discutir√°n y presentar√°n sus resultados cuando se indique en el tutorial."
  },
  {
    "objectID": "02.ProjectRules.html#espacio-de-trabajo",
    "href": "02.ProjectRules.html#espacio-de-trabajo",
    "title": "Preparemos todo para el proyecto",
    "section": "Espacio de trabajo",
    "text": "Espacio de trabajo\n\nEntra a tu cuenta en el servidor\nEntra al directorio del proyecto\n\ncd taller_metagenomica_pozol\n\n\n\n\n\n\nDirectorio de trabajo\n\n\n\nEl directorio principal del proyecto tiene la siguiente estructura:\nsrc/ Directorio donde se alojan los scripts\nresults/ Directorio que contiene los resultados de cada an√°lsis\nouts/ Directorio que contiene los archivos de error y de salida est√°ndar\n\n\n\n\nLa presente pr√°ctica s√≥lo es una representaci√≥n del flujo de trabajo para el an√°lisis metagen√≥mico, sin embargo, no sustituye los manuales de cada programa y el flujo puede variar dependiendo del tipo de datos y pregunta de investigaci√≥n, de hecho para fines del taller, con frecuencia se utilizan las lineas de comando m√°s simples para eficientar tiempo y recursos, t√≥malo en cuenta.\n\nCada programa tiene una ayuda y un manual de usuario, es importante revisarlo y conocer cada par√°metro que se ejecute. En terminal se puede consultar el manual con el comando man y tambi√©n se puede consultar la ayuda con -h o --help, por ejemplo fastqc -h.\n\n\n\n\n\n\nImportant\n\n\n\nüß† Para tenerlo presente\nEn bioinform√°tica cualquier l√≠nea de comandos generar√° un resultado, de ah√≠ a que esos resultados sean correctos puede haber una gran diferencia.\nEn cada paso detente a revisar la informaci√≥n de cada programa, lee el manual, visita foros de ayuda y selecciona los argumentos que se ajusten a las necesidades de tus datos."
  },
  {
    "objectID": "01.about.html",
    "href": "01.about.html",
    "title": "El pozol",
    "section": "",
    "text": "El pozol es un alimento √°cido, fermentado a partir de ma√≠z nixtamalizado, de importancia econ√≥mica y cultural, se consume desde tiempos prehisp√°nicos y se ha estudiado desde los a√±os 50s.\nAlgunos puntos importantes que conocemos son:\n\n\nNo se inocula y al final de su fermentaci√≥n tiene alta diversidad microbiana.\nEs muy nutritivo, tiene un alto contenido de amino√°cidos esenciales.\nEs considerado como prebi√≥tico, contiene fibras solubles y microorganismos ben√©ficos para la salud intestinal humana.\n\n\n\nüß¨üîäü¶† Imaginemos que se quiere impulsar la producci√≥n de esta bebida y para ello necesitan saber todo acerca de su naturaleza microbiana.\nUna importante industria alimenticia los contacta como expertos en ecolog√≠a microbiana y les pide ayuda para descubrir los siguientes puntos:\n\n\n¬øQu√© actores microbianos est√°n presentes durante el proceso de fermentaci√≥n?\n¬øC√≥mo ocurre la bioconversi√≥n del ma√≠z durante la fermentaci√≥n, qui√©n participa y c√≥mo lo hace? ¬øQu√© funciones metab√≥licas est√°n ocurriendo?\n¬øCambia la comunidad microbiana a lo largo del proceso?\n\n\nLa empresa secuenci√≥ cuatro puntos de fermentaci√≥n de muestras que se obtuvieron en un mercado de Campeche. Las muestras se secuenciaron con Illumina NextSeq500 con lecturas pareadas de 75 pb. Los datos est√°n p√∫blicos bajo el Bioproject: PRJNA648868\n\n\n\n\n\n\n\n\nImportante\n\n\n\nComo las muestras contienen ma√≠z, es indispensable remover las lecturas que correspondan al genoma del ma√≠z, no hacerlo producir√° un ensamble muy fragmentado, mayoritariamente del ma√≠z y poco microbiano.\nEl autor del art√≠culo amablemente nos proporcion√≥ sus muestras libres del ma√≠z y el c√≥digo que us√≥ para ello est√° disponible en un repositorio p√∫blico de GitHub.\n\n\nEl art√≠culo: L√≥pez-S√°nchez et al., 2023. Analysing the dynamics of the bacterial community in pozol, a Mexican fermented corn dough. 10.1099/mic.0.001355"
  },
  {
    "objectID": "00.index.html",
    "href": "00.index.html",
    "title": "Microbioma_del_pozol",
    "section": "",
    "text": "Taller de An√°lisis de Metagenomas, Reconstrucci√≥n de Genomas y An√°lisis de Amplicones.\nEn este taller introductorio aprenderemos a organizar un proyecto, analizar y visualizar datos metagen√≥micos; reconstruir genomas a partir de metagenomas (MAGs), a clasificar los MAGs taxon√≥micamente y a predecir sus genes e inferir su metabolismo."
  },
  {
    "objectID": "00.index.html#temario",
    "href": "00.index.html#temario",
    "title": "Microbioma_del_pozol",
    "section": "Temario",
    "text": "Temario\nJueves\n\n\n\nHora\nTema\n\n\n\n\n10:00 - 10:30\nIntroducci√≥n a la metagen√≥mica\n\n\n10:30 - 11:00\nEspacio de trabajo, recapitulaci√≥n.\n\n\n11:00 - 11:30\nEjercicio 1\n\n\n11:30 - 12:30\nReconstrucci√≥n de genomas\n\n\n12:30 - 12:45\nDescanso\n\n\n12:45 - 13:30\nRefinamiento\n\n\n13:30 - 14:00\nDesreplicaci√≥n\n\n\n14:00 - 15:00\nComida\n\n\n15:00 - 17:00\nEjercicio 2\n\n\n17:00 - 18:00\nDiscusi√≥n de resultados\n\n\n\nViernes\n\n\n\n\n\n\n\nHora\nTema\n\n\n\n\n10:00 - 11:00\nAsignaci√≥n taxon√≥mica\n\n\n11:00 - 12:00\nPredicci√≥n g√©nica\n\n\n12:00 - 12:30\nAnotaci√≥n\n\n\n12:30 - 12:45\nDescanso\n\n\n12:45- 13:30\nPl√°tica sobre el microbioma del chinicuil\n\n\n13:30 - 14:00\nRevisi√≥n de resultados\n\n\n14:00 - 15:00\nComida\n\n\n15:00 - 16:00\nRbims\n\n\n16:00 - 17:00\nOtras inferencias metab√≥licas y discusi√≥n de resultados"
  },
  {
    "objectID": "05.Metabolic.html",
    "href": "05.Metabolic.html",
    "title": "Metabolismo",
    "section": "",
    "text": "Ahora que ya tenemos los bins refinados, queremos saber qu√© capacidades metab√≥licas poseen. Para ello es necesario predecir sus genes y asignarles funci√≥n.\n\nPROKKA\nProkka es una herramienta √∫til, usa diferentes programas para predecir genes, secuencias codificantes, tRNAs, rRNAs. Hace la traducci√≥n de CDS a amino√°cidos y asigna funciones usando varias bases de datos.\n\n\n\n\n\nPara correrlo vamos a activar el ambiente en el que se aloja.\n\n\n\n\n\n\nActiva el ambiente para PROKKA\n\n\n\nconda activate mt-prokka\n\n\nTenemos el ambiente activo, ahora vamos a crear un directorio de resultados para prokka.\nmkdir -p results/11.prokka\nPara correrlo, podemos hacer un ciclo que nos permita anotar todos los bins.\nfor FASTA in $(ls results/10.gtdbtk/bins/); do LOCUSTAG=$(basename $FASTA .fasta); prokka --locustag \"${LOCUSTAG}_Scaffold\"  --prefix $LOCUSTAG --addgenes --addmrn --cpus 4 --outdir \"results/11.prokka/$LOCUSTAG\" \"results/10.gtdbtk/bins/$FASTA\" ;\ndone\n\n\n\n\n\n\nExplora\n\n\n\nMientras prokka se ejecuta en los bins que obtuviste, despliega la ayuda y discute:\n\n¬ø qu√© argumentos quitar√≠as o agregar√≠as?\nCu√°les te llamaron la atenci√≥n?\n\n\n\nDesactivemos el ambiente:\nconda deactivate\nAhora que tenemos las prote√≠nas predichas vamos a obtener m√°s anotaciones √∫tiles, usaremos kofam para esto.\n\n\nKofamScan\nKofamScan es una herramienta de anotaci√≥n, usa la base de datos KOfam de KEGG para obtener informaci√≥n sobre los genes que participan en diferentes rutas metab√≥licas.\nCreamos el script para kofam\nnano src/12.kofam.slurm\n#!/bin/bash\n#SBATHC -J kofam\n#SBATCH -t 0\n#SBATCH -n 4\n#SBATCH -e outs/12.kofam.err\n#SBATCH -o outs/12.kofam.out\n#SBATCH --export=ALL\n#SBATCH -p q2\n#SBATCH -w compute4\n\n# Limpiamos por si las moscas :P\nmodule purge\n\n# Caragmos el modulo para kofam\nmodule load kofam-scan/1.3.0/gcc/8.3.1-n3v4\n\n# Creamos el directorio para alojar los resultados\nmkdir -p results/12.kofam\n\n# Lo corremos\nfor FAA in $(ls results/11.prokka/*/*.faa); do\n    name=$(basename $FAA .faa)\n    exec_annotation $FAA \\\n        -o results/12.kofam/\"$name.txt\" \\\n        --report-unannotated \\\n        --cpu 4 \\\n        --tmp-dir results/12.kofam/\"tmp$name\" \\\n        -p /tmp/databases/KOfam/profiles/ \\\n        -k /tmp/databases/KOfam/ko_list\ndone\n\n# remover los directorios temporales\nrm -r results/12.kofam/tmp*\nEstos resultados ya los tienes en el directorio results/12.kofam por si esta tardando mucho.\nY ahora que ya tenemos los identificadores de KO para cada prote√≠na, vamos a filtrar y graficar el metabolismo de los bins.\n\n\nRbiMs\nRbiMs es un paquete de R muy √∫til para obtener la anotaci√≥n de cada KEGG ID y generar plots de esta informaci√≥n. Puede trabajar con anotaciones de KOFAM, Interpro o PFAM.\n\n\n\nRbiMs\n\n\nVamos al editor de Rstudio para correr RbiMs ‚ú®\nlibrary(tidyverse)\nlibrary(tidyr)\nlibrary(rbims)\nlibrary(readxl)\n\n#setwd(\"/home/alumnoX/taller_metagenomica_pozol/\")\n\n#A continuaci√≥n, leemos los resultados de KEGG \npozol_table &lt;- read_ko(data_kofam = \"results/12.kofam/\") \n\n#y los mapeamos con la base de datos de KEGG:\npozol_mapp &lt;- mapping_ko(pozol_table)\n\n#Nos centraremos en las v√≠as metab√≥licas relacionadas con la biosintesis de aminoacidos y vitaminas:\n\nOverview &lt;- c(\"Biosynthesis of amino acids\", \"Vitamin B6 metabolism\")\nAminoacids_metabolism_pozol &lt;- pozol_mapp %&gt;%\n  drop_na(Module_description) %&gt;%\n  get_subset_pathway(Pathway_description, Overview) \n\n#Visualizamos los datos con un gr√°fico de burbujas:\n\nplot_bubble(tibble_ko = Aminoacids_metabolism_pozol,\n            x_axis = Bin_name, \n            y_axis = Pathway_description,\n            analysis = \"KEGG\",\n            calc = \"Percentage\",\n            range_size = c(1, 10),\n            y_labs = FALSE,\n            x_labs = FALSE)  \n\n#A√±adiremos metadatos, como la taxonom√≠a:\n\nMetadatos &lt;- read_delim(\"results/10.gtdbtk/Metadatos.txt\", delim = \"\\t\")\n\n#Y generaremos un gr√°fico de burbujas con metadatos:\n\nplot_bubble(tibble_ko = Aminoacids_metabolism_pozol,\n            x_axis = Bin_name, \n            y_axis = Pathway_description,\n            analysis = \"KEGG\",\n            data_experiment = Metadatos,\n            calc = \"Percentage\",\n            color_character = Family,\n            range_size = c(1, 10),\n            y_labs = FALSE,\n            x_labs = FALSE) \n\n# Exploraci√≥n de una V√≠a Espec√≠fica\n# podemos explorar una sola v√≠a, como el ‚ÄúSecretion system,‚Äù y crear un mapa de calor para visualizar los genes relacionados con esta v√≠a:\n\nSecretion_system_pozol &lt;- pozol_mapp %&gt;%\n  drop_na(Cycle) %&gt;%\n  get_subset_pathway(Cycle, \"Secretion system\")\n\n#Y, finalmente, generamos un mapa de calor:\n\nplot_heatmap(tibble_ko = Secretion_system_pozol, \n             y_axis = Genes,\n             analysis = \"KEGG\",\n             calc = \"Binary\")\n\n#Tambi√©n podemos agregar metadatos para obtener una visi√≥n m√°s completa:\n\nplot_heatmap(tibble_ko = Secretion_system_pozol, \n             y_axis = Genes,\n             data_experiment = Metadatos,\n             order_x = Family,\n             analysis = \"KEGG\",\n             calc = \"Binary\")\n\nplot_heatmap(tibble_ko = Secretion_system_pozol, \n             y_axis = Genes,\n             data_experiment = Metadatos,\n             order_y = Pathway_cycle,\n             order_x = Family,\n             analysis = \"KEGG\",\n             calc = \"Binary\")\n\n# Explorar\ncolnames(pozol_mapp) \n\npozol_mapp %&gt;%\n  select(Cycle, Pathway_cycle, Pathway_description) %&gt;%\n  distinct()\n\n\n\n\n\n\n\nAntismash\nAdicionalmente podr√≠as anotar el metabolismo secundario de los bins siguiendo el flujo de an√°lisis propuestos en la lecci√≥n de Miner√≠a Gen√≥mica de Software Carpentry."
  }
]